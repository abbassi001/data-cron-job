#!/bin/bash

# Script am√©lior√© pour t√©l√©charger de grands volumes de donn√©es
# ============================================================

# Configuration
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_DIR="$(dirname "$SCRIPT_DIR")"
DATA_DIR="$PROJECT_DIR/data"
RAW_DIR="$DATA_DIR/raw"
LOG_DIR="$PROJECT_DIR/logs"
DATE=$(date +%Y-%m-%d)
LOG_FILE="$LOG_DIR/download_$DATE.log"

# Cr√©er les r√©pertoires s'ils n'existent pas
mkdir -p "$RAW_DIR" "$LOG_DIR"

# Initialiser le journal
echo "===== D√âBUT DU T√âL√âCHARGEMENT DE DONN√âES MASSIVES: $(date '+%Y-%m-%d %H:%M:%S') =====" | tee -a "$LOG_FILE"

# Sources de donn√©es volumineuses - environ 250+ MB combin√©es
# Format: NOM|URL|TYPE_FICHIER|TAILLE_ESTIM√âE_MB
SOURCES=(
  # Donn√©es m√©t√©orologiques compl√®tes - historique depuis 2010
  "METEO_HISTORIQUE|https://public.opendatasoft.com/api/explore/v2.1/catalog/datasets/donnees-synop-essentielles-omm/exports/csv?limit=1000000|CSV|80"
  
  # Donn√©es √©conomiques de l'INSEE (gros fichier)
  "INSEE_ECONOMIE|https://www.insee.fr/fr/statistiques/fichier/6544344/base-cc-emploi-pop-act-2019-csv.zip|ZIP|45"
  
  # Donn√©es environnementales europ√©ennes
  "ENVIRO_EU|https://www.eea.europa.eu/data-and-maps/data/waterbase-water-quality-icm-2/waterbase-water-quality-icm-2/waterbase-water-quality-data-results.csv/at_download/file|CSV|60"
  
  # Donn√©es de transport SNCF (volumineuse)
  "SNCF_DATA|https://ressources.data.sncf.com/api/v2/catalog/datasets/regularite-mensuelle-tgv-aqst/exports/csv?limit=-1&timezone=Europe%2FBerlin|CSV|35"
  
  # Donn√©es d√©mographiques mondiales
  "WORLD_POP|https://population.un.org/wpp/Download/Files/1_Indicators%20(Standard)/CSV_FILES/WPP2022_Demographic_Indicators_Medium.zip|ZIP|50"
)

# Fonction pour t√©l√©charger et journaliser avec support pour les grands fichiers
download_data() {
  local NAME=$1
  local URL=$2
  local TYPE=$3
  local SIZE_MB=$4
  local OUTPUT_FILE="$RAW_DIR/${NAME}_${DATE}.${TYPE,,}"
  
  echo "$(date '+%Y-%m-%d %H:%M:%S') - D√©but t√©l√©chargement de $NAME (taille estim√©e: ${SIZE_MB}MB) depuis $URL" | tee -a "$LOG_FILE"
  
  # Verification de l'espace disque
  local AVAILABLE_SPACE=$(df -m "$RAW_DIR" | awk 'NR==2 {print $4}')
  if [ "$AVAILABLE_SPACE" -lt $(($SIZE_MB * 2)) ]; then
    echo "‚ö†Ô∏è AVERTISSEMENT: Espace disque disponible ($AVAILABLE_SPACE MB) faible pour ce t√©l√©chargement (${SIZE_MB}MB). Poursuite quand m√™me..." | tee -a "$LOG_FILE"
  fi
  
  # T√©l√©chargement avec barre de progression et reprise
  # -C - pour permettre la reprise des t√©l√©chargements interrompus
  if curl -L --retry 5 --retry-delay 10 --max-time 3600 -C - --progress-bar -o "$OUTPUT_FILE" "$URL"; then
    if [ -s "$OUTPUT_FILE" ]; then
      local ACTUAL_SIZE=$(du -m "$OUTPUT_FILE" | cut -f1)
      echo "‚úÖ T√©l√©chargement r√©ussi: $OUTPUT_FILE (${ACTUAL_SIZE}MB)" | tee -a "$LOG_FILE"
      
      # Ajouter des m√©tadonn√©es d√©taill√©es
      echo "# Donn√©es t√©l√©charg√©es le: $DATE √† $(date '+%H:%M:%S')" > "$OUTPUT_FILE.meta"
      echo "# Source: $URL" >> "$OUTPUT_FILE.meta"
      echo "# Type: $TYPE" >> "$OUTPUT_FILE.meta"
      echo "# Taille: ${ACTUAL_SIZE}MB" >> "$OUTPUT_FILE.meta"
      
      # Traitement sp√©cial pour les ZIP - d√©compression
      if [[ "${TYPE,,}" == "zip" ]]; then
        echo "üì¶ D√©compression du fichier ZIP..." | tee -a "$LOG_FILE"
        EXTRACT_DIR="$RAW_DIR/${NAME}_${DATE}_extracted"
        mkdir -p "$EXTRACT_DIR"
        
        if unzip -q "$OUTPUT_FILE" -d "$EXTRACT_DIR"; then
          echo "‚úÖ D√©compression r√©ussie dans $EXTRACT_DIR" | tee -a "$LOG_FILE"
          
          # Liste des fichiers extraits
          echo "üìÑ Fichiers extraits:" | tee -a "$LOG_FILE"
          find "$EXTRACT_DIR" -type f | tee -a "$LOG_FILE"
          
          # Compter le nombre de fichiers CSV extraits
          CSV_COUNT=$(find "$EXTRACT_DIR" -name "*.csv" | wc -l)
          if [ "$CSV_COUNT" -gt 0 ]; then
            echo "üîç $CSV_COUNT fichier(s) CSV trouv√©(s) dans l'archive" | tee -a "$LOG_FILE"
          fi
        else
          echo "‚ùå √âchec de la d√©compression de $OUTPUT_FILE" | tee -a "$LOG_FILE"
        fi
      fi
      
      # Pour les CSV volumineux, afficher uniquement les 2 premi√®res et 2 derni√®res lignes
      if [[ "${TYPE,,}" == "csv" ]]; then
        echo "üìä Aper√ßu des donn√©es (2 premi√®res lignes):" | tee -a "$LOG_FILE"
        head -n 2 "$OUTPUT_FILE" | tee -a "$LOG_FILE"
        
        # Nombre total de lignes
        LINE_COUNT=$(wc -l < "$OUTPUT_FILE")
        echo "üìè Nombre total de lignes: $LINE_COUNT" | tee -a "$LOG_FILE"
        
        echo "üìä 2 derni√®res lignes:" | tee -a "$LOG_FILE"
        tail -n 2 "$OUTPUT_FILE" | tee -a "$LOG_FILE"
      fi
      
      # Calcul du hash pour les fichiers volumineux (plus lent mais plus s√ªr)
      echo "üîê Calcul du hash SHA256 (peut prendre un moment pour les gros fichiers)..." | tee -a "$LOG_FILE"
      SHA=$(sha256sum "$OUTPUT_FILE" | cut -d' ' -f1)
      echo "$SHA" > "$OUTPUT_FILE.sha256"
      echo "üîê Hash SHA256: $SHA" | tee -a "$LOG_FILE"
      
      return 0
    else
      echo "‚ùå Fichier t√©l√©charg√© vide: $NAME" | tee -a "$LOG_FILE"
      rm -f "$OUTPUT_FILE"
      return 1
    fi
  else
    echo "‚ùå √âchec du t√©l√©chargement de $NAME" | tee -a "$LOG_FILE"
    return 1
  fi
}

# Fonction pour v√©rifier l'acc√®s Internet
check_internet() {
  echo "üåê V√©rification de la connexion Internet..." | tee -a "$LOG_FILE"
  if ping -c 3 google.com > /dev/null 2>&1; then
    echo "‚úÖ Connexion Internet fonctionnelle" | tee -a "$LOG_FILE"
    return 0
  else
    echo "‚ùå Pas de connexion Internet d√©tect√©e" | tee -a "$LOG_FILE"
    return 1
  fi
}

# V√©rifier la connexion Internet avant de commencer
if ! check_internet; then
  echo "‚ö†Ô∏è Connexion Internet insuffisante pour t√©l√©charger des fichiers volumineux. Abandon." | tee -a "$LOG_FILE"
  exit 1
fi

# Calculer l'espace total n√©cessaire
TOTAL_SIZE=0
for SOURCE in "${SOURCES[@]}"; do
  IFS='|' read -r NAME URL TYPE SIZE_MB <<< "$SOURCE"
  TOTAL_SIZE=$((TOTAL_SIZE + SIZE_MB))
done

echo "üìä Volume total √† t√©l√©charger: environ ${TOTAL_SIZE}MB" | tee -a "$LOG_FILE"

# V√©rification d'espace disque global
AVAILABLE_SPACE=$(df -m "$RAW_DIR" | awk 'NR==2 {print $4}')
echo "üíæ Espace disque disponible: ${AVAILABLE_SPACE}MB" | tee -a "$LOG_FILE"

if [ "$AVAILABLE_SPACE" -lt $(($TOTAL_SIZE * 2)) ]; then
  echo "‚ö†Ô∏è AVERTISSEMENT: L'espace disque disponible ($AVAILABLE_SPACE MB) est faible pour le total des t√©l√©chargements (${TOTAL_SIZE}MB)" | tee -a "$LOG_FILE"
  read -p "Voulez-vous continuer quand m√™me? (o/n) " -n 1 -r
  echo
  if [[ ! $REPLY =~ ^[Oo]$ ]]; then
    echo "üõë T√©l√©chargement annul√© par l'utilisateur." | tee -a "$LOG_FILE"
    exit 1
  fi
fi

# T√©l√©charger toutes les sources
echo "üöÄ D√©but des t√©l√©chargements massifs (${#SOURCES[@]} sources, environ ${TOTAL_SIZE}MB au total)" | tee -a "$LOG_FILE"

SUCCESS_COUNT=0
FAILED_COUNT=0

for SOURCE in "${SOURCES[@]}"; do
  IFS='|' read -r NAME URL TYPE SIZE_MB <<< "$SOURCE"
  
  echo "üì• Traitement de la source: $NAME (${SIZE_MB}MB)" | tee -a "$LOG_FILE"
  
  if download_data "$NAME" "$URL" "$TYPE" "$SIZE_MB"; then
    SUCCESS_COUNT=$((SUCCESS_COUNT + 1))
  else
    FAILED_COUNT=$((FAILED_COUNT + 1))
  fi
  
  echo "------------------------------------------------" | tee -a "$LOG_FILE"
done

# R√©sum√© final
echo "===== R√âSUM√â DU T√âL√âCHARGEMENT =====" | tee -a "$LOG_FILE"
echo "‚úÖ T√©l√©chargements r√©ussis: $SUCCESS_COUNT" | tee -a "$LOG_FILE"
echo "‚ùå T√©l√©chargements √©chou√©s: $FAILED_COUNT" | tee -a "$LOG_FILE"
echo "üíæ Espace disque utilis√©: $(du -sh "$RAW_DIR" | cut -f1)" | tee -a "$LOG_FILE"
echo "===== FIN DES T√âL√âCHARGEMENTS MASSIFS: $(date '+%Y-%m-%d %H:%M:%S') =====" | tee -a "$LOG_FILE"

# Retourner un code d'erreur si tous les t√©l√©chargements ont √©chou√©
if [ "$SUCCESS_COUNT" -eq 0 ]; then
  echo "‚ùå ERREUR: Tous les t√©l√©chargements ont √©chou√©." | tee -a "$LOG_FILE"
  exit 1
fi

exit 0